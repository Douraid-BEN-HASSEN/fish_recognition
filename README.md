# Fish Individual Recognition using Computer Vision & Deep Learning

<img src="images/predict_result.gif" alt="Exemple de dÃ©tection"/>

Ce projet vise Ã  rÃ©soudre un dÃ©fi complexe : **reconnaÃ®tre individuellement des poissons quasiment identiques** (taille, couleur, forme) dans un aquarium en mouvement, en combinant computer vision et deep learning.

## ğŸ› ï¸ Architecture de la Solution

1. **GÃ©nÃ©ration de dataset synthÃ©tique** avec Unity pour l'annotation rapide
2. **DÃ©tection et pose estimation** avec YOLO
3. **Transformation des keypoints en masques** (profil/face)
4. **Classification individuelle** basÃ©e sur les morphologies subtiles

## ğŸ“¦ Dataset

- **Annotations** : 23 keypoints anatomiques par poisson
- **Outils** : GÃ©nÃ©ration procÃ©durale sous Unity â†’ *<b>YOLOPoseExporter.cs<b>*
- **Exemples d'annotation** :

<img src="images/pose_annotation_1.jpg" alt="pose_annotation_1" width="50%"/><img src="images/pose_annotation_2.jpg" alt="pose_annotation_2" width="50%"/>
<img src="images/pose_annotation_3.jpg" alt="pose_annotation_3" width="50%"/><img src="images/pose_annotation_4.jpg" alt="pose_annotation_4" width="50%"/>

## ğŸ§  ModÃ¨le YOLO pour Pose Estimation

### Configuration
- **ModÃ¨le** : YOLO11-pose (yolo11s-pose)
- **Keypoints** : 23 points anatomiques

    <img src="images/keypoints_name.png" alt="Keypoints name" width="25%"/>

- **EntrÃ©e** : 640x640 pixels

### Courbes d'apprentissage (400 epochs)
<img src="images/pose_metrics.png" alt="Pose metrics"/>

### Pose predictions
<img src="images/pose_predictions.gif" alt="Pose predictions"/>

## âœ¨ Normalisation des Keypoints â†’ Masques

MÃ©thode convertissant les keypoints en masques pour capturer les subtilitÃ©s morphologiques:

1. Alignement des points clÃ©s :
    - Profile â†’ mouth - caudalStart
    - Face â†’ leftEye - rightEye
2. GÃ©nÃ©ration de silhouette
3. Normalisation perspective (longeur du poisson)

**Exemples de transformation** :
| Keypoints | Masque | Type de masque |
|-----------|---------------|------------|
| <img src="images/keypoints_1.png" alt="keypoints_1"/> | <img src="images/mask_keypoints_1.png" alt="mask_keypoints_1" width="50%"/> | Profil |
| <img src="images/keypoints_2.png" alt="keypoints_2"/> | <img src="images/mask_keypoints_2.png" alt="mask_keypoints_2" width="50%"/> | Profil |
| <img src="images/keypoints_3.png" alt="keypoints_3"/> | <img src="images/mask_keypoints_3.png" alt="mask_keypoints_3" width="50%"/> | Face |
| <img src="images/keypoints_4.png" alt="keypoints_4"/> | <img src="images/mask_keypoints_4.png" alt="mask_keypoints_4" width="50%"/> | Face |


## ğŸ¯ Classification Individuelle

### Architecture :

ParamÃ¨tres Globaux
| ParamÃ¨tre | Valeur |
|-----------|---------------|
| Input Shape | (46,) |
| Nombre de Classes | 3 (3 poissons) |
| Optimiseur | Adam avec Cyclical Learning Rate |
| Taux d'apprentissage initial | 0.001 |
| Beta1 | 0.9 |
| Beta2 | 0.999 |
| Epsilon | 1e-7 |
| Fonction de Loss | sparse_categorical_crossentropy |

SchÃ©ma de l'Architecture
```
InputLayer(shape=(46,))
â”‚
â”œâ”€ Dense(256, activation='relu', kernel_initializer='he_normal')
â”œâ”€ BatchNormalization()
â”œâ”€ Dropout(0.2)
â”‚
â”œâ”€ [Bloc RÃ©siduel 1]
â”‚   â”œâ”€ Dense(256, activation='relu', L2=1e-5) â†’ BatchNorm â†’ Dropout(0.3)
â”‚   â”œâ”€ Dense(256, activation='relu', L2=1e-5) â†’ BatchNorm
â”‚   â””â”€ Add() + Dropout(0.3)  # Connexion rÃ©siduelle
â”‚
â”œâ”€ Dense(128, activation='relu', L2=1e-5) â†’ BatchNorm â†’ Dropout(0.35)
â”‚
â”œâ”€ [Bloc RÃ©siduel 2]
â”‚   â”œâ”€ Dense(128, activation='relu', L2=1e-5) â†’ BatchNorm â†’ Dropout(0.35)
â”‚   â”œâ”€ Dense(128, activation='relu', L2=1e-5) â†’ BatchNorm
â”‚   â””â”€ Add() + Dropout(0.35)  # Connexion rÃ©siduelle
â”‚
â”œâ”€ Dense(64, activation='relu', L2=1e-5) â†’ BatchNorm â†’ Dropout(0.4)
â”‚
â”œâ”€ [TÃªte de Classification]
â”‚   â”œâ”€ Dense(32, activation='relu') â†’ BatchNorm â†’ Dropout(0.5)
â”‚   â””â”€ Dense(num_classes, activation='softmax')
â”‚
Model: "Functional"
```

CaractÃ©ristiques ClÃ©s
1. Connexions RÃ©siduelles

    - Deux blocs rÃ©siduels pour Ã©viter le vanishing gradient.

    - Utilisation de Add() pour fusionner les entrÃ©es/sorties.

2. RÃ©gularisation

    - Dropout progressif (de 0.2 Ã  0.5).

    - L2 Regularization (1e-5) sur les couches denses.

    - Batch Normalization aprÃ¨s chaque couche dense.

3. Optimisation

    - Adam avec des paramÃ¨tres classiques (beta1, beta2).

    - PrÃ©paration pour un Cyclical Learning Rate (Ã  implÃ©menter via un callback).

### Face model
- **Metrics** :

<img src="images/face_trainingsetstats2.png" alt="Trainning metrics Face" width="15%"/>

- **Courbes d'apprentissage (436 epochs)** :

<img src="images/face_classifier_training_metrics.png" alt="Matrice de confusion Face" width="50%"/>

- **Matrice de confusion** :

<img src="images/face_trainingset.png" alt="Matrice de confusion Face" width="25%"/>
<img src="images/face_trainingsetstats.png" alt="Trainning metrics Face" width="50%"/>

### Profile model
- **Metrics** :

<img src="images/profile_trainingsetstats2.png" alt="Trainning metrics Profile" width="15%"/>

- **Courbes d'apprentissage (150 epochs)** :

<img src="images/profile_classifier_training_metrics.png" alt="Matrice de confusion Face" width="50%"/>

- **Matrice de confusion** :

<img src="images/profile_trainingset.png" alt="Matrice de confusion Profile" width="25%"/>
<img src="images/profile_trainingsetstats.png" alt="Trainning metrics Profile" width="50%"/>


## ğŸš€ Utilisation

```bash
# Installation
pip install -r requirements.txt

# InfÃ©rence
python predict.py